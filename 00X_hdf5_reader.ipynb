{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#  Copyright 2025 United Kingdom Research and Innovation\n",
    "#  Copyright 2025 The University of Manchester\n",
    "#  Copyright 2025 Technical University of Denmark\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "#\n",
    "#   Authored by:    Hannah Robarts (UKRI-STFC)\n",
    "#                   Laura Murgatroyd (UKRI-STFC)\n",
    "#                   Margaret Duff (UKRI-STFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8230db",
   "metadata": {},
   "source": [
    "# HDF5 reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5659ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1 - 3D parallel beam steel sphere example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af057a06",
   "metadata": {},
   "source": [
    "This is taken from the CIL deep dive [05_esrf_pipeline.ipynb](https://github.com/TomographicImaging/CIL-Demos/blob/main/demos/4_Deep_Dives/05_esrf_pipeline.ipynb). All credit should go to those authors. \n",
    "\n",
    "It is a work in progress.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903afe4c",
   "metadata": {},
   "source": [
    "## Data format: NXTomo\n",
    "\n",
    "This example uses dataset tomo_00065 from the TomoBank [[1](https://iopscience.iop.org/article/10.1088/1361-6501/aa9c19)] multidistance dataset. The sample is a steel sphere measured at various propagation distances to demonstrate the effect of propagation based phase contrast imaging.\n",
    "\n",
    "The tomo_00065.h5 dataset can be retrieved from https://tomobank.readthedocs.io/en/latest/source/data/docs.data.phasecontrast.html#multi-distance using:\n",
    "\n",
    "`wget https://g-a0400.fd635.8443.data.globus.org/tomo_00064_to_00067/tomo_00065.h5`\n",
    "\n",
    "[1] De Carlo, Francesco, et al. “TomoBank: a tomographic data repository for computational x-ray science.” Measurement Science and Technology 29.3 (2018): 034004. http://www.doi.org/10.1088/1361-6501/aa9c19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09603f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIL methods\n",
    "from cil.framework import DataContainer\n",
    "from cil.utilities.display import show2D, show_geometry\n",
    "from cil.utilities.jupyter import islicer\n",
    "from cil.io.utilities import HDF5_utilities\n",
    "from cil.io import TIFFWriter\n",
    "from cil.processors import Normaliser, RingRemover, TransmissionAbsorptionConverter, CentreOfRotationCorrector, PaganinProcessor\n",
    "from cil.recon import FBP\n",
    "# Additional packages\n",
    "import numpy as np # conda install numpy\n",
    "import matplotlib.pyplot as plt # conda install matplotlib\n",
    "# Custom methods\n",
    "from readers.hdf5_parallel_reader import HDF5_ParallelDataReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca848982",
   "metadata": {},
   "source": [
    "## CIL Version\n",
    "\n",
    "This notebook was developed using CIL v25.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba0049",
   "metadata": {},
   "source": [
    "Update this filepath to where you have saved the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tomo_00065.h5'\n",
    "HDF5_utilities.print_metadata(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55eb96",
   "metadata": {},
   "source": [
    "We use the generic 'HDF5_ParallelDataReader', set the paths to the required information in the metadata and then read in the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12511076",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = HDF5_ParallelDataReader(filename, \n",
    "                                 dataset_path=('exchange/data'),\n",
    "                                 distance_units='mm', angle_units='degree')\n",
    "                                \n",
    "\n",
    "reader.configure_angles(angles_path='exchange/theta', HDF5_units='degree')\n",
    "\n",
    "reader.configure_pixel_sizes('measurement/instrument/detector/x_actual_pixel_size',\n",
    "                             'measurement/instrument/detector/y_actual_pixel_size',\n",
    "                             HDF5_units = 'um')\n",
    "\n",
    "reader.configure_normalisation_data(flatfield_path='exchange/data_white',\n",
    "                                    darkfield_path='exchange/data_dark')\n",
    "\n",
    "# Alternatively, you can set the sample to detector distance directly as a float value rather than passing a path to the value in the HDF5 file\n",
    "reader.configure_sample_detector_distance(sample_detector_distance=58, HDF5_units='mm') \n",
    "\n",
    "data = reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_geometry(data.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d44e0d",
   "metadata": {},
   "source": [
    "Let's normalise the data using the flat and dark fields that were seen in the hdf5 file and read in by the reader. First lets visualise them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([reader.flatfield, reader.darkfield], title=['Flatfield', 'Darkfield'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76212df",
   "metadata": {},
   "source": [
    "We see that show2D has chosen to display slice 1 and slice 2 of the flat and dark field objects. Lets look at the shapes in more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Flatfield shape, ', reader.flatfield.shape)\n",
    "print('Darkfield shape, ', reader.darkfield.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9cdcd4",
   "metadata": {},
   "source": [
    "There are 4 fla and 4 darks. We take averages of these images and pass the resulting images to the CIL normaliser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ab082",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_flat = np.mean(reader.flatfield, axis = 0)\n",
    "average_dark = np.mean(reader.darkfield, axis = 0)\n",
    "processor = Normaliser(flat_field=average_flat, dark_field=average_dark)\n",
    "processor.set_input(data)\n",
    "data_normalised = processor.get_output()\n",
    "\n",
    "# Use the show2D method to check the effect of the normalisation\n",
    "show2D([data, data_normalised],\n",
    "       title=['Before Normalisation', 'After Normalisation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.plugins.tigre import FBP\n",
    "\n",
    "reconstruction = FBP(acquisition_geometry=data.geometry)(data_normalised)\n",
    "\n",
    "islicer(reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79c49e",
   "metadata": {},
   "source": [
    "## Example 2 - 2D fan beam multi-material example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac99f2",
   "metadata": {},
   "source": [
    "Let's try another dataset! This time a 2D fan beam dataset available on zenodo: \n",
    "\n",
    "Khalil, M., Kehres, J., & Mustafa, W. (2023). Hyperspectral 2D fan-beam X-ray CT dataset of 5 materials (1.0.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.8307932. \n",
    "\n",
    "Download the data and set the path to the data and, as before, let's view the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sino25_interpol_line.h5'\n",
    "HDF5_utilities.print_metadata(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f216d",
   "metadata": {},
   "source": [
    "There is nothing stored in the hdf5 file :(. However, there is lots of information on the zenodo page that we can use! \n",
    "\n",
    "\"Hyperspectral X-ray CT dataset acquired at the DTU 3D imaging center. The phantom consists of 5 materials: Aluminium (10 mm) and PVC (7.8 mm) in solid blocks. Sugar, H2O2, and H2O in circular glass containers.\n",
    "\n",
    "3D array with dimension: 128 x 370 x 258 < channel, angle, horizontal >\n",
    "\n",
    " \n",
    "\n",
    "Detector parameters:\n",
    "\n",
    "Number of detector pixels: 258 (concatenated from 2 detector modules with 128 pixels each and 2 pixel interpolated across a gap between detectors)\n",
    "\n",
    "Pixel size: 0.077 cm\n",
    "\n",
    "Sep=0.153  Pixels' gap length (cm)\n",
    "\n",
    "det_space=(ndet)*pixel_size+Sep # physical width of detector in cm (pixels*pixel_size), including the gap\n",
    "\n",
    " \n",
    "\n",
    "Acquisition Parameters\n",
    "\n",
    "360 # Angular span of projections in degrees\n",
    "\n",
    "370 # Number of projections. note: last projection taken is not a duplicate of the first projection. At angle: 360/370 degrees from first projection.\n",
    "\n",
    "115.0 # Source-Detector distance in cm\n",
    "\n",
    "0 # Vertical source shift from perfect placement\n",
    "\n",
    "0 # Vertical detector shift from perfect placement\n",
    "\n",
    "57.5 # Source-AxisOfRotation distance in cm\n",
    "\n",
    " \n",
    "\n",
    "rot_axis_x = 0 # x-position offset of AxisOfRotation\n",
    "\n",
    "rot_axis_y = 0 # y-position offset of AxisOfRotation\"\n",
    "\n",
    "Let's set up the hdf5 reader! This time we use the cone beam version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readers.hdf5_cone_reader import HDF5_ConeDataReader\n",
    "\n",
    "reader = HDF5_ConeDataReader(filename, \n",
    "                                 dataset_path=('data'),\n",
    "                                 distance_units='cm', angle_units='degree', dimension_labels=['channel', 'angle', 'horizontal'])\n",
    "                                \n",
    "\n",
    "reader.configure_angles(angles=[ -i*360/370 for i in range(370)], HDF5_units='degree')\n",
    "\n",
    "reader.configure_pixel_sizes(pixel_size_x=0.077,\n",
    "                             HDF5_units = 'cm')\n",
    "\n",
    "reader.configure_source_detector_distance(source_detector_distance=115, HDF5_units='cm')\n",
    "reader.configure_sample_detector_distance(sample_detector_distance=115-57, HDF5_units='cm')\n",
    "\n",
    "reader.configure_channels(num_channels=128)\n",
    "data = reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a530bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_geometry(data.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e514b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = data.geometry.get_ImageGeometry().allocate(0)\n",
    "\n",
    "for i in range(0,128,10):\n",
    "    single_data = data.get_slice(channel=i)\n",
    "    print(single_data)\n",
    "    if i==0:\n",
    "        recon = FBP(acquisition_geometry=single_data.geometry)\n",
    "    show2D(recon(single_data), title=f'Channel {i}', fix_range=(0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46485a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "margaret_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
